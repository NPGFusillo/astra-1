#!/usr/bin/env python3
import click

# Common options.
@click.group()
@click.option("-v", "verbose", default=False, is_flag=True, help="verbose mode")
@click.pass_context
def cli(context, verbose):
    context.ensure_object(dict)
    context.obj["verbose"] = verbose
    # Overwrite settings in ~/.astra/astra.yml
    # from astra import log
    # log.set_level(10 if verbose else 20)


@cli.command()
@click.option("--drop-tables", is_flag=True)
def initdb(drop_tables):
    """Initialize the database."""
    from time import sleep
    from astra.utils import log
    from astra.models import (
        base,
        apogee,
        apogeenet,
        aspcap,
        #boss,
        #classifier,
        #lineforest,
        #madgics,
        #mdwarftype,
        #slam,
        #snow_white,
        source,
        spectrum,
        #the_payne
    )
    
    models = base.BaseModel.__subclasses__()
    with base.database.atomic():
        if drop_tables:
            log.warning(f"Dropping database tables in 10 seconds..")
            sleep(10)
            base.database.drop_tables(models, cascade=True)
        
        base.database.create_tables(models)
    log.info(f"Created {len(models)} database tables: {models}")
    
    return None



@cli.command(context_settings=dict(ignore_unknown_options=True))
@click.option("--slurm", is_flag=True, default=False, help="Execute through Slurm (see --slurm-profile)")
@click.option("--slurm-profile", default=None, help="Use Slurm profile specified in Astra config file. If None is given, it will default to the profile for the task name, or `default`.")
@click.option("--slurm-dir", default=None)
@click.option("--limit", default=None, type=int)
@click.option("--kwargs-path")
@click.argument("task")
@click.argument("spectra", nargs=-1)
def execute(slurm, slurm_profile, slurm_dir, limit, kwargs_path, task, spectra):
    """
    Execute a task on one or many spectra.
    """
    # Resolve spectrum ids.
    if len(spectra) == 0:
        raise click.UsageError("No spectral model or spectrum identifiers given.")

    import os
    import sys
    from astra import config
    from astra.utils import expand_path, log, callable

    import pickle
    from inspect import getfullargspec
    from tqdm import tqdm
    from peewee import chunked, JOIN

    from astra import models
    from astra.models.spectrum import Spectrum, SpectrumMixin

    kwargs = {}
    if kwargs_path is not None:
        with open(kwargs_path, "rb") as fp:
            kwargs = pickle.load(fp)

    # Parse any additional keyword arguments which unfortunately get lumped into `spectra`.
    # TODO: THere must be a nicer way to parse this using click.
    _spectra = []
    for arg in spectra:
        if arg.startswith("--"):
            k, *v = arg[2:].split("=")
            k = k.replace("-", "_")
            kwargs[k] = "=".join(v).strip('"')
        else:
            _spectra.append(arg)

    
    

    # Do some cleverness about the task name.
    for prefix in ("", "astra.", "astra.pipelines.", f"astra.pipelines.{task}."):
        try:
            resolved_task = f"{prefix}{task}"
            f = callable(resolved_task)
        except:
            None
        else:
            if prefix:
                log.info(f"Resolved '{task}' -> '{resolved_task}'")
            break
    else:
        # Raise exception on the no-prefix case.
        f = callable(task)

    # TODO: This is all a bit of spaghetti code. Refactor

    if slurm:
        # Check that there is any work to do before submitting a job.

        try:
            spectrum_ids = list(map(int, _spectra))
        except ValueError:
            if len(_spectra) > 1:
                raise NotImplementedError("Only one spectrum model allowed for now. This can be changed.")
            
            model_name, = _spectra
            spectrum_model = getattr(models, model_name)
            try:
                output_model = getfullargspec(f).annotations["return"].__args__[0]
            except:
                raise ValueError(f"Cannot infer output model for task {f}, is it missing a type annotation?")

            # Query for spectra that does not have a result in this output model
            iterable = (
                spectrum_model
                .select()
                .join(
                    output_model,
                    JOIN.LEFT_OUTER,
                    on=(spectrum_model.spectrum_id == output_model.spectrum_id)
                )
                .where(output_model.spectrum_id.is_null())
                .limit(limit)
            )
            total = limit or iterable.count()
            log.info(f"Found at least {total} {model_name} spectra that do not have results in {output_model}")

        else:
            total = len(spectrum_ids)

        if total == 0:
            # Nothing to do.
            log.info(f"No spectra to process.")
            sys.exit(0)
    

        from astra.utils.slurm import SlurmTask, SlurmJob

        # Resolve slurm profile.
        slurm_profile_config = config.get("slurm", dict(profiles={})).get("profiles", {})
        if slurm_profile is not None:
            if slurm_profile not in slurm_profile_config:
                raise click.BadArgumentUsage(f"Cannot find Slurm profile '{slurm_profile}' in Astra config.")            
        else:     
            try_slurm_profile_names = (resolved_task, resolved_task.split(".")[-1], "default")
            for slurm_profile in try_slurm_profile_names:
                if slurm_profile in slurm_profile_config:
                    log.info(f"Using Slurm profile '{slurm_profile}'")
                    break
            else:
                raise click.BadOptionUsage(f"Cannot find any Slurm profile in Astra config. Use `--slurm-profile PROFILE` to specify. Tried: {', '.join(slurm_profile_config)}")
            
        slurm_kwds = slurm_profile_config[slurm_profile]

        # Submit this job. #TODO: Is there a way for Click to reconstruct the command for us?
        command = "astra execute "
        if limit:
            command += f"--limit {limit} "
        if kwargs_path:
            command += f"--kwargs-path {kwargs_path} "
        command += f"{resolved_task} "
        command += " ".join(spectra)

        if slurm_dir is None:
            from datetime import datetime
            from tempfile import mkdtemp
            slurm_dir = mkdtemp(prefix=f"{datetime.now().strftime('%Y-%m-%d')}-{resolved_task.split('.')[-1]}-", dir=expand_path(f"$PBS/"))
            os.chmod(slurm_dir, 0o755)
            log.info(f"Using Slurm directory: {slurm_dir}")    
            job_name = f"{os.path.basename(slurm_dir)}"
        else:
            os.makedirs(slurm_dir, exist_ok=True)
            job_name = f"{resolved_task.split('.')[-1]}"

        slurm_job = SlurmJob(
            [
                SlurmTask([command])
            ],
            job_name,
            dir=slurm_dir,
            **slurm_kwds,
        )
        slurm_job_id = slurm_job.submit()

        click.echo(f"{slurm_job_id}")
        sys.exit(0)



    try:
        spectrum_ids = list(map(int, _spectra))
    except ValueError:
        if len(_spectra) > 1:
            raise NotImplementedError("Only one spectrum model allowed for now. This can be changed.")
        
        model_name, = _spectra
        spectrum_model = getattr(models, model_name)
        try:
            output_model = getfullargspec(f).annotations["return"].__args__[0]
        except:
            raise ValueError(f"Cannot infer output model for task {f}, is it missing a type annotation?")

        # Query for spectra that does not have a result in this output model
        iterable = (
            spectrum_model
            .select()
            .join(
                output_model,
                JOIN.LEFT_OUTER,
                on=(spectrum_model.spectrum_id == output_model.spectrum_id)
            )
            .where(output_model.spectrum_id.is_null())
            .limit(limit)
        )
        total = limit or iterable.count()
    
    else:            
        if not spectrum_ids:
            spectrum_ids.extend(kwargs.pop("spectra", []))
        else:
            if "spectra" in kwargs:
                raise ValueError("`spectra` given in `kwargs_path` and in command line")
    
        # Figure out which model it is
        if spectrum_ids:                
            example = Spectrum.get(spectrum_ids[0])
            spectrum_model = None
            for expr, field in example.dependencies():
                if SpectrumMixin not in field.model.__mro__:
                    continue
                try:
                    q = list(field.model.select().where(expr))
                except:
                    continue
                else:
                    if q:
                        spectrum_model = field.model
                        log.info(f"Identified input spectra as type `{spectrum_model}`")
                        break
            
            log.warning(f"All given spectrum identifiers should come from the same model type")

            # SQLite has a limit on how many SQL variables can be used in a transaction.
            def yield_spectrum_chunks():
                for chunk in chunked(spectrum_ids, 10_000):
                    yield from (
                        spectrum_model
                        .select()
                        .where(spectrum_model.spectrum_id.in_(chunk))
                    )

            iterable = yield_spectrum_chunks()
            total = len(spectrum_ids)
        else:
            raise click.UsageError("Could not resolve spectrum identifiers.")

    for result in tqdm(f(iterable, **kwargs), total=total, unit=" spectra"):
        None
    
    return None



@cli.command()
@click.argument("paths", nargs=-1)
def run(paths, **kwargs):
    """Execute one or many tasks."""
    import os
    import json
    from importlib import import_module
    from astra.utils import log, expand_path
    from astra.database.astradb import DataProduct
    from tqdm import tqdm

    for path in paths:
        log.info(f"Running {path}")
        with open(path, "r") as fp:
            content = json.load(fp)
         
        instructions = [content] if isinstance(content, dict) else content
        N = len(instructions)
        for i, instruction in enumerate(instructions, start=1):
            log.info(f"Starting on instruction {i}/{N} in {path}")

            task_kwargs = instruction.get("task_kwargs", {})

            # A couple of unfortunate hacks to fix instructions that were incomplete.
            if (instruction["task_callable"] == "astra.contrib.aspcap.abundances.aspcap_abundances"):
                if "pwd" not in task_kwargs:
                    # This one will fail.
                    log.warning(f"Skipping {i}-th (1-indexed) instruction because it's ASPCAP abundances without a pwd")
                    continue
                
                # Check if outputs already exist.
                pwd = task_kwargs["pwd"]
                if os.path.exists(os.path.join(expand_path(pwd), "stdout")):
                    log.warning(F"Skipping {i}-th (1-indexed) instruction because it's ASPCAP abundances and the outputs already exist")
                    continue            

            # Get the task executable.
            module_name, function_name = instruction["task_callable"].rsplit(".", 1)
            module = import_module(module_name)
            task_callable = getattr(module, function_name)

            has_data_products = "data_product" in task_kwargs # TODO: this special key should be defined elsewhere
            if has_data_products:
                # Resolve the data products
                input_data_products = task_kwargs.pop("data_product", [])
                if isinstance(input_data_products, str):
                    input_data_products = json.loads(input_data_products)
                # The same data product can appear in this list multiple times, and we want to preserve order.
                q = DataProduct.select().where(DataProduct.id << input_data_products)
                unique_data_products = { dp.id: dp for dp in q }
                task_kwargs["data_product"] = [unique_data_products[dp_id] for dp_id in input_data_products]
                
            log.info(f"Executing..")
            try:
                results = task_callable(**task_kwargs)
                for result in results:
                    None
            except:
                log.exception(f"Exception in {task_callable} with {task_kwargs}")
                raise
                continue


    log.info(f"Done")
    
    # Remove the path now that we're done.
    #try:
    #    os.unlink(path)
    #except:
    #    None



if __name__ == "__main__":
    cli(obj=dict())
